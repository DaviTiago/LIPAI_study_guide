{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6290d399",
   "metadata": {},
   "source": [
    "### Estruturação dos módulos de PyTorch\n",
    "\n",
    "```python\n",
    "import torch\n",
    "```\n",
    "* [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) - Tensores (arrays N-D)\n",
    "* [`torch.nn`](https://pytorch.org/docs/stable/nn.html) - Redes Neurais (_**N**eural **N**etworks_)\n",
    "* [`torch.optim`](https://pytorch.org/docs/stable/optim.html) - Otimização (_**Optim**ization_)\n",
    "* [`torch.data`](https://pytorch.org/docs/stable/data.html) - *Datasets* e Ferramentas de Streaming de Dados\n",
    "* [`torch.autograd`](https://pytorch.org/docs/stable/autograd.html) - Diferenciação Automática (_**Auto**matic Differentiation_)\n",
    "* [`torch.vision`](https://pytorch.org/docs/stable/torchvision/index.html) - Ferramentas de Manipulação de Imagens e Visão Computacional\n",
    "* [`torch.audio`](https://pytorch.org/audio/stable/index.html) - Ferramentas de Manipulação de Áudio\n",
    "* [`torch.jit`](https://pytorch.org/docs/stable/jit.html) - Compilação _**j**ust-**i**n-**t**ime_ de modelos PyTorch em binários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccfc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# MNIST dataset\n",
    "root_path = 'data'\n",
    "\n",
    "# Pequena transformação para tensores e normalizando o tamanho\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Train/Test Datasets\n",
    "full_train_dataset = torchvision.datasets.MNIST(root=root_path, train=True, transform=trans, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=root_path, train=False, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "666007df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676fafe",
   "metadata": {},
   "source": [
    "### 2. Divisão em Treino e Validação\n",
    "\n",
    "Usamos `random_split` para dividir o `full_train_dataset` em um conjunto de treino e um de validação. Uma divisão comum é 80% para treino e 20% para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f86f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset de treino: 48000\n",
      "Tamanho do dataset de validação: 12000\n",
      "Tamanho do dataset de teste: 10000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "# Definir os tamanhos para treino e validação\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "# Dividir o dataset\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Tamanho do dataset de treino: {len(train_dataset)}\")\n",
    "print(f\"Tamanho do dataset de validação: {len(val_dataset)}\")\n",
    "print(f\"Tamanho do dataset de teste: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3a636",
   "metadata": {},
   "source": [
    "### 3. Criar DataLoaders\n",
    "\n",
    "DataLoaders são responsáveis por carregar os dados em lotes (batches), o que é essencial para o treinamento de redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05329a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881afd5",
   "metadata": {},
   "source": [
    "### 4. Definir o Modelo (CNN)\n",
    "\n",
    "Aqui definimos uma arquitetura de Rede Neural Convolucional (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a60cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a543bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=1000, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(7 * 7 * 64, 1000),\n",
    "            nn.ReLU())\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Instancia o Model()\n",
    "model = ConvNet()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073cc8a1",
   "metadata": {},
   "source": [
    "Quantidade de parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac9d9431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3199106"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eaded69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# Hiperparâmetros\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "epochs = 6\n",
    "\n",
    "# Instânciar o Otimizador Adam\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575f4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Isto tem que retornar True\n",
    "import torch\n",
    "is_cuda_avaliable = torch.cuda.is_available()\n",
    "print(is_cuda_avaliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ce0f4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Sua GPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\davit\\Desktop\\MeusProjetos\\Iniciação Científica\\LIPAI\\LIPAI_study_guide\\Onboarding\\src\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:584\u001b[39m, in \u001b[36mget_device_name\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_name\u001b[39m(device: \u001b[33m\"\u001b[39m\u001b[33mDevice\u001b[39m\u001b[33m\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    573\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[32m    574\u001b[39m \n\u001b[32m    575\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m \u001b[33;03m        str: the name of the device\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\davit\\Desktop\\MeusProjetos\\Iniciação Científica\\LIPAI\\LIPAI_study_guide\\Onboarding\\src\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:616\u001b[39m, in \u001b[36mget_device_properties\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_properties\u001b[39m(device: \u001b[33m\"\u001b[39m\u001b[33mDevice\u001b[39m\u001b[33m\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m) -> _CudaDeviceProperties:\n\u001b[32m    605\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[32m    606\u001b[39m \n\u001b[32m    607\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    614\u001b[39m \u001b[33;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[32m    615\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[32m    617\u001b[39m     device = _get_device_index(device, optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device >= device_count():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\davit\\Desktop\\MeusProjetos\\Iniciação Científica\\LIPAI\\LIPAI_study_guide\\Onboarding\\src\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Sua GPU\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5fd21",
   "metadata": {},
   "source": [
    "### Enviar Modelo para GPU (se disponível) EX:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b33d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando o dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import device\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando o dispositivo: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o Modelo\n",
    "total_step = len(train_loader)  # quantos batches eu tenho\n",
    "\n",
    "# Listas vazias\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "valid_acc_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "model.to(device) # mover o modelo para GPU EX: 1\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # modo de treino\n",
    "    \n",
    "    train_loss = 0\n",
    "    correct =0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.to(device)  # mover os dados para GPU EX: 1\n",
    "        labels = labels.to(device)  # mover os dados para GPU EX: 1\n",
    "                \n",
    "        # Gera a propagação (feed forward)\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calcula a função-custo\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "\n",
    "        # Retro-propagação (Backprop) e a otimização com Adam\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Acurácia\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Época [{epoch+1}/{epochs}], Step [{i+1}/{total_step}], Custo: {round(loss.item(), 3)}, Acurácia: {round((correct / total) * 100, 3)}\")\n",
    "            \n",
    "    #Media de treino\n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "    train_acc_list.append((correct / total) * 100)\n",
    "\n",
    "#Ex 2 Validação do Modelo\n",
    "    model.eval()  # modo de avaliação\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)  # mover os dados para GPU EX: 1\n",
    "            labels = labels.to(device)  # mover os dados para GPU EX: 1\n",
    "\n",
    "            # Gera a propagação (feed forward)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calcula a função-custo\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "           \n",
    "\n",
    "            # Acurácia\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Média de validação\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    valid_loss_list.append(val_loss)\n",
    "    valid_acc_list.append(val_acc)\n",
    "\n",
    "    print(f'Validação - Época [{epoch+1}/{epochs}], Custo: {round(val_loss, 3)}, Acurácia: {round(val_acc, 3)}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_step = len(train_loader)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---- Treino ----\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Acumula loss e acurácia\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Época [{epoch+1}/{epochs}], Step [{i+1}/{total_step}], \"\n",
    "                  f\"Custo: {loss.item():.3f}, \"\n",
    "                  f\"Acurácia: {(correct/total)*100:.2f}%\")\n",
    "\n",
    "    # Médias de treino\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # ---- Validação ----\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc = 100 * correct / total\n",
    "    valid_loss_list.append(val_loss)\n",
    "    valid_acc_list.append(val_acc)\n",
    "\n",
    "    print(f\"Validação - Época [{epoch+1}/{epochs}], \"\n",
    "          f\"Custo: {val_loss:.3f}, Acurácia: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e5b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - O treinamento imprime o custo e a acurácia no terminal, mas os resultados são mais fáceis de interpretar visualmente. Então, armazene o histórico de perda e acurácia de treino e validação a cada época em listas. Ao final do treinamento, utilize a biblioteca matplotlib para plotar gráficos da perda e da acurácia ao longo das épocas. Isso oferece uma visão clara sobre a convergência do modelo e o surgimento de overfitting.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotando a perda de treino e validação\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss_list, label='Perda de Treino')\n",
    "plt.plot(valid_loss_list, label='Perda de Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.title('Perda de Treino e Validação ao Longo das Épocas')\n",
    "plt.grid()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc_list, label='Acurácia de Treino')\n",
    "plt.plot(valid_acc_list, label='Acurácia de Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia (%)')\n",
    "plt.legend()\n",
    "plt.title('Acurácia de Treino e Validação ao Longo das Épocas')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Um ponto importante em aprendizagem profunda envolve salvar o modelo treinado para uso posterior. Demonstre como salvar o estado do modelo (model.state_dict()) com torch.save(). Salve o modelo que apresentou o melhor desempenho no conjunto de validação. Mostre também como carregar esses pesos de volta em uma instância do modelo. \n",
    "    \n",
    "# Salva o melhor modelo\n",
    "from tabnanny import check\n",
    "\n",
    "\n",
    "checkpoint={\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': epochs,\n",
    "    'train_loss_list': train_loss_list,\n",
    "    'train_acc_list': train_acc_list,\n",
    "    'valid_loss_list': valid_loss_list,\n",
    "    'valid_acc_list': valid_acc_list\n",
    "}\n",
    "torch.save(checkpoint, 'best_model.pth')\n",
    "# Carrega o melhor modelo\n",
    "model = ConvNet() # instancia o modelo\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate) # instancia o otimizador\n",
    "checkpoint = torch.load('best_model.pth') # carrega o checkpoint\n",
    "model.load_state_dict(checkpoint['model_state_dict']) # carrega os pesos\n",
    "epochs = checkpoint['epoch'] \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
